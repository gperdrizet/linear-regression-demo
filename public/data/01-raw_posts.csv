impressions,post_url,post_text,word_count,n_tags,external_link,media,post_date
26,https://www.linkedin.com/posts/activity-7364619857406877698-1KCD?utm_source=share&utm_medium=member_desktop&rcm=ACoAAC1jSQYB21OnvTZl_t_atKlYgs255ng7rVU,"Friday slide day! What to know from weeks 1 and 2 to be set-up for success in the 4Geeks Academy datascience bootcamp Python basics, Git  GitHub, Pandas, SQL and data visualization. Phew! Python machinelearning Git Pandas SQL datavisualization",38,7,False,True,2025-08-22
2389,https://www.linkedin.com/posts/activity-7364272724883456002-Np8w?utm_source=share&utm_medium=member_desktop&rcm=ACoAAC1jSQYB21OnvTZl_t_atKlYgs255ng7rVU,"Has anyone tried marimo yet? Sounds great Python notebooks that can be run interactively, as a script, imported as a module or deployed directly as a web app. Seems like it fixes a lot of the issues inherent in Jupyter notebooks. Im a little concerned about how the prohibition on re-defining variables across cells would effect data science workflows. Regardless, excited to give it a shot! Python notebooks as dataflow graphs reactive, reproducible, and reusable python DevOps",77,2,True,True,2025-08-21
43,https://www.linkedin.com/posts/activity-7363893819345444865-XHW8?utm_source=share&utm_medium=member_desktop&rcm=ACoAAC1jSQYB21OnvTZl_t_atKlYgs255ng7rVU,"Large object promisors are comming to Git. Excited about this - how many times have I accidentally tracked an intermediate datafile, or been frustrated by LFS - too many times. Would be so cool push large files to dedicated storage automatically. The future of large files in Git is Git git guthub datascience opensource",54,4,True,True,2025-08-20
50,https://www.linkedin.com/posts/activity-7363555374638977024-TuTp?utm_source=share&utm_medium=member_desktop&rcm=ACoAAC1jSQYB21OnvTZl_t_atKlYgs255ng7rVU,"New paper by Chengshuai Zhao et al. Arizona State University concludes that CoT reasoning is superficial and not the product of genuine inductive inference. Instead, it is still heavily constrained by the training data distribution and only simulates reasoning-like text. To test this, the authors define three axies of generalization task, length and format. They then asses model performance on each, while systematically varying the degree of difference between training and test distributions. To see it - take a look a figure 4. CoT reasoning is no help in generalizing to new tasks, unless the model has has some amount of supervised fine-tuning on the same data. CMP, POOD and OOD represent test datasets with increasing distance from the training data. This could imply that CoT is not fundamentally different from other prompting strategies - but I would have liked to see different prompting strategies included as a control. Zhao et al. 2025 Is Chain-of-Thought Reasoning of LLMs a Mirage? A Data Distribution Lens LLMs CoT reasoningmodels",167,3,True,False,2025-08-19
40,https://www.linkedin.com/posts/activity-7363185447830806530-bYPw?utm_source=share&utm_medium=member_desktop&rcm=ACoAAC1jSQYB21OnvTZl_t_atKlYgs255ng7rVU,"Nice blog post by Deane Barker - I love writing in markdown and use it for tons of stuff README files, how-to guides, student instructions, my own notes. But I didnt know about Custom Elements and what you can do by embedding them in markdown. The Joy of Mixing Custom Elements, Web Components, and Markdown webhosting",56,1,True,True,2025-08-18
37,https://www.linkedin.com/posts/activity-7362083158453854208-59QE?utm_source=share&utm_medium=member_desktop&rcm=ACoAAC1jSQYB21OnvTZl_t_atKlYgs255ng7rVU,"Friday slide day! Three slide intro to SQL for data science! 4Geeks Academy datascience Python machinelearning SQLite, MySQL PostgreSQL",19,7,False,True,2025-08-15
35,https://www.linkedin.com/posts/activity-7361758524017721344-0gnL?utm_source=share&utm_medium=member_desktop&rcm=ACoAAC1jSQYB21OnvTZl_t_atKlYgs255ng7rVU,Curious to hear if anyone has tried self-hosting GPT-OSS-120B. Heres a Reddit post where the author claims to get good performance with only 8 GB VRAM on llama.cpp by running just the attention layers on GPU with the rest offloaded to CPU. GPT-OSS-120B runs on 8 GB VRAM LLMs selfhosting,50,2,True,True,2025-08-14
46,https://www.linkedin.com/posts/activity-7361373635736944641-W2_t?utm_source=share&utm_medium=member_desktop&rcm=ACoAAC1jSQYB21OnvTZl_t_atKlYgs255ng7rVU,"Anyone know of something like this in Python? Id love to use it with my data science students. I know I could just set it up myself, but I like the public leader board aspect. Its a great motivator and gives the opportunity to learn from other solutions The One Billion Row Challenge Python datascience",55,2,True,True,2025-08-13
215,https://www.linkedin.com/posts/activity-7361003579853152256-BxgN?utm_source=share&utm_medium=member_desktop&rcm=ACoAAC1jSQYB21OnvTZl_t_atKlYgs255ng7rVU,"Self-Taught Engineers Often Outperform - Michael Bastos. As ex-college faculty and a self taught programmer/engineer I love this sentiment. If someone has accrued skills by tinkering, it speaks very highly of their motivation, problem solving ability and practical understanding. The image is some motivation for those working towards tinker-born mastery - its a Beowulf style cluster I built from Ebay laptops and other recycled parts. Sorry for the potato-quality photo, its from the early 2010s! I learned a huge amount about Linux, networking and parallel computing along the way - good times! DIY motivation learning",95,3,True,False,2025-08-12
21,https://www.linkedin.com/posts/activity-7360652472421425153-wfmc?utm_source=share&utm_medium=member_desktop&rcm=ACoAAC1jSQYB21OnvTZl_t_atKlYgs255ng7rVU,"Useful inference API pricing quick reference for the major models/providers. Google Gemini 2.0 Flash-Lite is least expensive at 0.07/0.30 per million input/output tokens, while Open AIs GPT-o1-pro is most expensive at 150/600 - yikes! Price Per Token LLMs cloud inference",40,3,False,False,2025-08-11
64,https://www.linkedin.com/posts/activity-7359546467058941952-dysw?utm_source=share&utm_medium=member_desktop&rcm=ACoAAC1jSQYB21OnvTZl_t_atKlYgs255ng7rVU,"Friday slide day! Crash overview of plotting in Python with Matplotlib and Seaborn in just three slides for 4Geeks Academy datascience bootcamp. Includes some fun bad plot examples. If youve seen any terrible plots recently, Id love to add them to my collection! Python machinelearning datavisualization seaborn",47,5,False,True,2025-08-08
62,https://www.linkedin.com/posts/activity-7359310515937890304-6msk?utm_source=share&utm_medium=member_desktop&rcm=ACoAAC1jSQYB21OnvTZl_t_atKlYgs255ng7rVU,That was fast! GPT-5 already available for Copilot in VS Code. Busy week for OpenAI. Has anyone taken it for a test drive yet? AI LLMs metacoding,27,3,False,False,2025-08-07
50,https://www.linkedin.com/posts/activity-7359180267757993986-Ztix?utm_source=share&utm_medium=member_desktop&rcm=ACoAAC1jSQYB21OnvTZl_t_atKlYgs255ng7rVU,A significant portion of the benefit gained from writing about or preparing a talk on a topic is the clarity and understanding you will gain. Had this realization when I was a graduate researcher. Preparing my first work-in-progress talk pushed the project months ahead by forcing me to organize and clarify my ideas. The same is true of writing code! Writing is Thinking,63,0,True,True,2025-08-07
54,https://www.linkedin.com/posts/activity-7358848074166771712-pmzo?utm_source=share&utm_medium=member_desktop&rcm=ACoAAC1jSQYB21OnvTZl_t_atKlYgs255ng7rVU,"Cool new image dataset from Yuhan Wang et al. University of California, Santa Cruz - 1.5 million GPT-4o edited image pairs with prompt from OmniEdit, HQ-Edit, and UltraEdit benchmark datasets. GPT-IMAGE-EDIT-1.5M A Million-Scale, GPT-Generated Image Dataset HuggingFace dataset GitHub repository GPT generativeAI computervision",43,3,True,False,2025-08-06
85,https://www.linkedin.com/posts/activity-7358570610857263106-uwH5?utm_source=share&utm_medium=member_desktop&rcm=ACoAAC1jSQYB21OnvTZl_t_atKlYgs255ng7rVU,"Wow, did not see this one coming - OpenAI just uploaded two open weight models to Hugging Face! Whats the catch? Its a pair of MoE models with 128/32 experts, 117B/21B total params respectively and 128k context lengths. The published benchmarks show slightly weaker performance relative to o4-mini and o3. Open models by OpenAI GitHub repo first commit 3 hrs ago gpt-oss-20b gpt-oss-120b LLMs opensource",65,2,True,False,2025-08-05
60,https://www.linkedin.com/posts/activity-7358481976946819073-dqEb?utm_source=share&utm_medium=member_desktop&rcm=ACoAAC1jSQYB21OnvTZl_t_atKlYgs255ng7rVU,"Has anyone tried these yet? New pair of open source foundation models from Z.ai GLM-4.5  GLM-4.5-Air, MoE with 355B/32B active and 106B/12B active parameters respectively. The claimed performance is impressive and the release post includes some cool looking demos including slide creation and fullstack development. GLM-4.5 Reasoning, Coding, and Agentic Abilities LLMs MoE OpenSource",54,3,False,False,2025-08-05
45,https://www.linkedin.com/posts/activity-7358115766308589568-k-41?utm_source=share&utm_medium=member_desktop&rcm=ACoAAC1jSQYB21OnvTZl_t_atKlYgs255ng7rVU,"This looks interesting - new open source ML model training experiment tracker from Hugging Face. Open source, local first, and doesnt require a database to store results. Introducing Trackio A Lightweight Experiment Tracking Library from Hugging Face machinelearning deeplearning LLMs",40,3,True,False,2025-08-04
133,https://www.linkedin.com/posts/activity-7357009728742268928-rFlq?utm_source=share&utm_medium=member_desktop&rcm=ACoAAC1jSQYB21OnvTZl_t_atKlYgs255ng7rVU,Friday slide day! Simple introduction to Pandas in three slides for my 4Geeks Academy datascience cohorts. What Pandas methods do you use most? Python machinelearning Pandas,26,4,False,True,2025-08-01
72,https://www.linkedin.com/posts/activity-7356653611772174338-n9Yz?utm_source=share&utm_medium=member_desktop&rcm=ACoAAC1jSQYB21OnvTZl_t_atKlYgs255ng7rVU,"With Google Chrome deep-sixing uBlock Origin by dropping Manifest V2 support, maybe its time to consider other options. Heres a great introduction to and tips and tricks for Firefox from Kaushik Gopal - Principal Engineer at Instacart. My favorite tip is setting browser.tabs.insertAfterCurrent to true! How to Firefox",48,0,True,True,2025-07-31
64,https://www.linkedin.com/posts/activity-7356282039794290688-ESW9?utm_source=share&utm_medium=member_desktop&rcm=ACoAAC1jSQYB21OnvTZl_t_atKlYgs255ng7rVU,"NORC at the University of Chicago poll found 60 of people over the age of 18 have used AI for search as of July 2025, with 37 reporting daily use. How US adults are using AI, according to AP-NORC polling AI LLMs websearch",43,3,True,False,2025-07-30
62,https://www.linkedin.com/posts/activity-7356266058464301056-OmRo?utm_source=share&utm_medium=member_desktop&rcm=ACoAAC1jSQYB21OnvTZl_t_atKlYgs255ng7rVU,Interesting tidbit! Why your website should be just at or under 14 kB at least for the first page load. Definitely learned something new about TCP slow start and ACK! Why your website should be under 14kB in size,39,0,True,True,2025-07-30
98,https://www.linkedin.com/posts/activity-7355933894820413440-u3lq?utm_source=share&utm_medium=member_desktop&rcm=ACoAAC1jSQYB21OnvTZl_t_atKlYgs255ng7rVU,"Awesome overview of LLM architecture in 2025 for anyone who wants to stay up to date on things like rotational positional embedding and grouped-query attention. Wild how far this stuff has come, but also how similar current models are to those of 5 years ago. Sebastian Raschka, PhD, The Big LLM Architecture Comparison",53,0,True,False,2025-07-29
61,https://www.linkedin.com/posts/activity-7355590389564600321-4gRA?utm_source=share&utm_medium=member_desktop&rcm=ACoAAC1jSQYB21OnvTZl_t_atKlYgs255ng7rVU,Great simple AsyncIO walk-through and example by Alexander Nordin! A conceptual overview of the ideas and objects which power asyncio Python,21,1,True,True,2025-07-28
94,https://www.linkedin.com/posts/activity-7354473034000285696-8uOS?utm_source=share&utm_medium=member_desktop&rcm=ACoAAC1jSQYB21OnvTZl_t_atKlYgs255ng7rVU,Friday slide day! What to know from the pre-work assignments to be set-up for success in the 4Geeks Academy datascience bootcamp. python machinelearning,23,3,False,True,2025-07-25
210,https://www.linkedin.com/posts/activity-7354125739572531203-iUzZ?utm_source=share&utm_medium=member_desktop&rcm=ACoAAC1jSQYB21OnvTZl_t_atKlYgs255ng7rVU,Great interactive visual explainer of transformer model architecture by the Polo Club of Data Science at Georgia Tech. TRANSFORMER EXPLAINER LLMs,21,1,True,False,2025-07-24
115,https://www.linkedin.com/posts/activity-7353772124966141952-JmxG?utm_source=share&utm_medium=member_desktop&rcm=ACoAAC1jSQYB21OnvTZl_t_atKlYgs255ng7rVU,"Amazing to see how fast Gradio MCP servers are moving, even just since the hackathon last month! Love the improvements to the client-local file workflow. Hugging Face, Five Big Improvements to Gradio MCP Servers MCP Agents",36,2,True,True,2025-07-23
137,https://www.linkedin.com/posts/activity-7353757790546345989-Evp0?utm_source=share&utm_medium=member_desktop&rcm=ACoAAC1jSQYB21OnvTZl_t_atKlYgs255ng7rVU,Check this out - Cerebras Systems just launched Qwen3-235B for cloud inference. Cost is 0.60/1.20 per million input/output tokens. Compare that to 3/15 for Claude Sonnet 4... They also claim generation rates of 1000 tokens a second and greater. Cerebras Launches Qwen3-235B Worlds Fastest Frontier AI Model with Full 131K Context Support,52,0,True,True,2025-07-23
91,https://www.linkedin.com/posts/activity-7353584087409782784-o4GI?utm_source=share&utm_medium=member_desktop&rcm=ACoAAC1jSQYB21OnvTZl_t_atKlYgs255ng7rVU,ICML 2025 Experts benchmark now on Kaggle. Crowd sourced set of 30 tasks collected from participants at the 2025 conference in Vancouver. Many others on the new benchmarks platform as well. Introducing Kaggle Benchmarks,34,0,True,True,2025-07-23
98,https://www.linkedin.com/posts/activity-7353566723054129152-LUKg?utm_source=share&utm_medium=member_desktop&rcm=ACoAAC1jSQYB21OnvTZl_t_atKlYgs255ng7rVU,First Python 3.14 release candidate is here. Particularly intrested to try out Asyncio introspection and the ability to attach to a running process with PDB. Python3.14.0rc,26,0,True,True,2025-07-22
133,https://www.linkedin.com/posts/activity-7353562072875474944-Igrp?utm_source=share&utm_medium=member_desktop&rcm=ACoAAC1jSQYB21OnvTZl_t_atKlYgs255ng7rVU,"Qwen3-coder series just announced - 480B avalible now on Hugging Face, with more sizes to come. Excited about this one, Qwens coder variants are a great match for smolagents CodeAgent! Qwen3-Coder Agentic Coding in the World",36,1,True,False,2025-07-22
45,https://www.linkedin.com/posts/activity-7353404726228443137-acLy?utm_source=share&utm_medium=member_desktop&rcm=ACoAAC1jSQYB21OnvTZl_t_atKlYgs255ng7rVU,"Fully Homomorphic Encryption allows computations on encrypted data - very cool technology, I did not know this was a thing! Think about sending data to third party service - we have good security solutions for when data is in transit and when its stored, but the third party has to decrypt the data to do anything with it. As soon as they do, it becomes vulnerable to leaks, breaches and/or misuse. Problem has been that the technique is too slow to be practical for most things - but its been getting faster 8x per year since 2011. Imagine encrypted LLM inference - the provider never sees your input, or the response! Baris Ozman Fully Homomorphic Encryption and the Dawn of A Truly Private Internet cybersecurity",125,1,False,False,2025-07-22
110,https://www.linkedin.com/posts/activity-7353053768420057088-GHZk?utm_source=share&utm_medium=member_desktop&rcm=ACoAAC1jSQYB21OnvTZl_t_atKlYgs255ng7rVU,"Great, fun read for anyone who really wants to understand the basics of how Git actually works. Creating a commit object by hand kinda blew my mind. Also, never really realized how simple and clever content addressable storage is...  Drew Silcock - Artisanal Handcrafted Git Repositories",46,0,True,True,2025-07-21
85,https://www.linkedin.com/posts/activity-7351960533866057728-kV-H?utm_source=share&utm_medium=member_desktop&rcm=ACoAAC1jSQYB21OnvTZl_t_atKlYgs255ng7rVU,Heres the new ChatGPT agent from OpenAI - anyone got a GAIA benchmark result yet? Introducing ChatGPT agent bridging research and action ChatGPT agents,24,2,True,True,2025-07-18
143,https://www.linkedin.com/posts/activity-7351936305221496833-ip7p?utm_source=share&utm_medium=member_desktop&rcm=ACoAAC1jSQYB21OnvTZl_t_atKlYgs255ng7rVU,"Friday slide day! What to expect in my 4Geeks Academy datascience bootcamp cohorts topics, day to day schedule for class sessions and some extra tips! python machinelearning",27,3,False,True,2025-07-18
104,https://www.linkedin.com/posts/activity-7351573926709215237-6d82?utm_source=share&utm_medium=member_desktop&rcm=ACoAAC1jSQYB21OnvTZl_t_atKlYgs255ng7rVU,Cool new miniproject for my 4Geeks Academy data science bootcamp students - write your own optimization algorithm to fit a linear model to toy data. Great way to start thinking about how models are fitted to data. Easy and fast to get up and running with GitHub Codespaces. Try it out and let me know what you think! Linear Regression  Optimization Assignment python datascience optimization regression,66,4,True,False,2025-07-17
114,https://www.linkedin.com/posts/activity-7351211518996217858-nSoU?utm_source=share&utm_medium=member_desktop&rcm=ACoAAC1jSQYB21OnvTZl_t_atKlYgs255ng7rVU,"New study suggests that AI coding tools actually slow experienced developers working on mature projects down. The difference from prior work? This study uses labeled screen recordings rather than lines of code or commits to measure productivity. Time spent prompting, waiting for and then reviewing generated code outweighed gains in speed. This mirrors my own experience - metacoding at the function level keeps me in that terrible productivity trap of constant wait times of more than about 30 seconds, but less than about 5 minutes - to short to switch tasks and do anything else meaningful, but just long enough to get distracted. Joel B. et al. METR Measuring the Impact of Early-2025 AI on Experienced Open-Source Developer Productivity Cursor Windsurf Copilot",122,3,True,False,2025-07-16
1226,https://www.linkedin.com/posts/activity-7350849154819981313-cQjA?utm_source=share&utm_medium=member_desktop&rcm=ACoAAC1jSQYB21OnvTZl_t_atKlYgs255ng7rVU,Do LLMs really utilize those impressively long context windows? New research from Kelly Hong et al. at Chroma suggests maybe not. The standard NIAH benchmark may be too easy - more complex benchmarks experience pronounced reductions in performance as input length grows. Context Rot How Increasing Input Tokens Impacts LLM Performance ClaudeSonnet GPT Qwen Gemini,55,4,True,True,2025-07-15
180,https://www.linkedin.com/posts/activity-7350480436067753985-mr24?utm_source=share&utm_medium=member_desktop&rcm=ACoAAC1jSQYB21OnvTZl_t_atKlYgs255ng7rVU,CoT prompting and RLHF tend to increase undesirable outputs like empty rhetoric and unverified claims. New paper Machine Bullshit Characterizing the Emergent Disregard for Truth in Large Language Models by Kaiqu Liang Princeton University et al LLMs,37,1,True,False,2025-07-14
403,https://www.linkedin.com/posts/activity-7349413484427706368-cIt1?utm_source=share&utm_medium=member_desktop&rcm=ACoAAC1jSQYB21OnvTZl_t_atKlYgs255ng7rVU,Nice guide to LLM inference by BentoML. Comprehensive and succinct at the same time. Covers everything from infrence basics like prefill and decode to advanced deployment techniques like prompt aware load balancing AIengineering,33,1,True,False,2025-07-11
102,https://www.linkedin.com/posts/activity-7348693804339679233-QIaO?utm_source=share&utm_medium=member_desktop&rcm=ACoAAC1jSQYB21OnvTZl_t_atKlYgs255ng7rVU,"Hugging Face just released smolLM3 - the model itself is cool small, efficent and open source with 128k context. But the blog post is even cooler, covering how it was built in detail - from model architecture and data mixtures to evaluation. If you are intrested in how modern LLMs are built and trained, its highly worth a read",59,0,True,False,2025-07-09
371,https://www.linkedin.com/posts/activity-7348308188871467009-U7Rc?utm_source=share&utm_medium=member_desktop&rcm=ACoAAC1jSQYB21OnvTZl_t_atKlYgs255ng7rVU,Just finished the Hugging Face agents course! Built a multi-agent system for the GAIA benchmark and learned a ton along the way. Together AI and Modal were invaluable for hosting models including Quen-2.5-coder-32B and DeepSeek-V3. Trick was to implement Anthropic style agent memory summarization to keep the context length under control for complex tasks employing multiple turns/agents/tools. Course covered everything agent basics to managed multi-agent agent systems and custom tools. Check out my course repository on GitHub,77,0,True,False,2025-07-08
132,https://www.linkedin.com/posts/activity-7341832420721147904-fyQB?utm_source=share&utm_medium=member_desktop&rcm=ACoAAC1jSQYB21OnvTZl_t_atKlYgs255ng7rVU,"Just finished the first project in the Hugging Face agents course! Pleasantly surprised how easy smolagebts is - implemented a generic multi-turn agent with image generation, text-to-speech and web-search/site crawling tools. - Try it on HuggingFace spaces - GitHub repository",40,0,True,False,2025-06-20
4894,https://www.linkedin.com/posts/activity-7339322548637097984-5Wun?utm_source=share&utm_medium=member_desktop&rcm=ACoAAC1jSQYB21OnvTZl_t_atKlYgs255ng7rVU,"Congrats to everyone who finished the Gradio Agents  MCP Hackathon on Hugging Face! My build is a pair of apps an agentic RSS feed reader Im calling RASS Retrieval Augmented Simple Syndication, and an MCP server providing the custom RSS feed tools. Try it out on HF spaces or take a look a the main project repository on GitHub. I had a blast and learned a ton. It was my first time using Model Context Protocol, I now have a much better understanding of AsyncIO, SSE and multi-turn agent prompting. Thanks to Anthropic, Modal and all of the sponsors for the API credits. RASS client on HF spaces Main project repository on GitHub",113,0,True,False,2025-06-13
241,https://www.linkedin.com/posts/activity-7338709009497042946-FXCa?utm_source=share&utm_medium=member_desktop&rcm=ACoAAC1jSQYB21OnvTZl_t_atKlYgs255ng7rVU,"Congrats GitHub, AasishPokhrel and the entire Open Source Software community for reaching 1 billion repositories on GitHub!",17,0,True,True,2025-06-11
620,https://www.linkedin.com/posts/activity-7336757806936580097-vk03?utm_source=share&utm_medium=member_desktop&rcm=ACoAAC1jSQYB21OnvTZl_t_atKlYgs255ng7rVU,"For folks new to MCP like me and building clients in Hugging Face Spaces with Gradio for the Agents  MCP Hackathon, I found this GitHub repository by Adel Zaalouk extremely helpful. I learned a ton adapting it to my build",40,0,True,True,2025-06-06
5584,https://www.linkedin.com/posts/activity-7335793827640741895-EXdm?utm_source=share&utm_medium=member_desktop&rcm=ACoAAC1jSQYB21OnvTZl_t_atKlYgs255ng7rVU,"Heres the plan for the Hugging Face Gradio Agents  MCP Hackathon. Recently, I have been rediscovering how awesome RSS feeds are but need a way to wade though the volume of content from my subscriptions - so, lets build it! Seems like a lot to wire up in the next 6 days, but I think it will be a good test of how far the tools have come!",68,0,False,False,2025-06-03
341,https://www.linkedin.com/posts/activity-7335656199821955074-QuFL?utm_source=share&utm_medium=member_desktop&rcm=ACoAAC1jSQYB21OnvTZl_t_atKlYgs255ng7rVU,"Nice whitepaper from Googles Lee Boonstra Software Engineer, Tech Lead. Covers types of prompting strategies with examples and best practices.",20,0,True,False,2025-06-03
209,https://www.linkedin.com/posts/activity-7335387792262242305-6eUo?utm_source=share&utm_medium=member_desktop&rcm=ACoAAC1jSQYB21OnvTZl_t_atKlYgs255ng7rVU,Excited to build some cool stuff this week for the Gradio Agents  MCP Hackathon! Thanks to Gradio for organizing and Modal Labs and the other sponsors for the compute credits!,30,0,True,False,2025-06-02
253,https://www.linkedin.com/posts/activity-7334557781951193089-ULTH?utm_source=share&utm_medium=member_desktop&rcm=ACoAAC1jSQYB21OnvTZl_t_atKlYgs255ng7rVU,"Insightful blog post that looks beyond the hype and discusses ways to adapt ourselves and our workflows to maximize the benefit of AI development tools. Written by Annie Cherkaev, Netflix compute platform engineer and computer science PhD.",37,0,True,True,2025-05-31
448,https://www.linkedin.com/posts/activity-7334245007815585792-mYNz?utm_source=share&utm_medium=member_desktop&rcm=ACoAAC1jSQYB21OnvTZl_t_atKlYgs255ng7rVU,"Anybody read this in detail yet? Was just submitted to arXiv yesterday. Jenny Zhang and Shengran Hu describe a Darwin-Godel Machine. Its a meta-learning approach designed to optimize coding agents. A frozen foundation model iteratively generates and samples from growing evolutionary tree of agents, evaluating each generations performance on coding benchmarks. Intuitively sounds great! Paper Post",56,0,True,False,2025-05-30
320,https://www.linkedin.com/posts/activity-7334210811072057344-nBv0?utm_source=share&utm_medium=member_desktop&rcm=ACoAAC1jSQYB21OnvTZl_t_atKlYgs255ng7rVU,"Interesting discussion of how to build the ability to have good intuition over a wide range of technical topics in engineering, with a focus on LLMs. By Sean Goedecke, software engineer at GitHub and author of Software Engineering after the Vibe Shift.",42,0,True,True,2025-05-30
336,https://www.linkedin.com/posts/activity-7239596662011146259-qap4?utm_source=share&utm_medium=member_desktop&rcm=ACoAAC1jSQYB21OnvTZl_t_atKlYgs255ng7rVU,Anyone else attending? Looking forward to hearing about data for AI/ML on Google Cloud. GoogleCloud Data MachineLearningEngineering,17,3,False,True,2024-09-11
900,https://www.linkedin.com/posts/activity-7201911481813061632-gwF-?utm_source=share&utm_medium=member_desktop&rcm=ACoAAC1jSQYB21OnvTZl_t_atKlYgs255ng7rVU,"When pretraining a base model or fine-tuning an already pre-trained model, how much data is needed? How does downstream performance scale with dataset size? Berivan Isik et al. 2024 at Stanford University and Google Research undertake a systematic investigation of multi-lingual translation using T5-3B and the English, German, French and Romanian subsets of the MC4 dataset to find out. They determine that for reasonably matched pretraining and fine-tuning datasets, BLEU score on downstream tasks follows a log law see below. Other interesting observations - BLEU score on fine-tuning data is a better behaved and reliable performance metric than cross-entropy. - Downstream BLEU score can be fit and extrapolated from small-scale pretraining experiments and used to guide dataset/resource allocation. - If a large amount of fine-tuning data is available, pretraining becomes unnecessary. - It is important for pretraining and fine-tuning data to be as well matched as possible. ğ—£ğ—®ğ—½ğ—²ğ—¿ technology machinelearning AI languagemodels NLP fine-tuning transfer-learning",155,7,True,False,2024-05-30
574,https://www.linkedin.com/posts/activity-7200113925252595713-NgpC?utm_source=share&utm_medium=member_desktop&rcm=ACoAAC1jSQYB21OnvTZl_t_atKlYgs255ng7rVU,"Caveat emptor is that fancy new LLM really making good use of its impressively long context? Probably not. Cheng-Ping Hsieh et al., in a new paper from NVIDIA show that many popular models fail to achieve LlaMA2-7B level performance at their stated context length table 3 below. The authors provide a new benchmark called RULER which improves on the standard needle-in-a-haystack test using multiple, configurable task types giving a better representation of how well a model uses context. They also provided tests of 10 popular models ranging in size from 7B to 8x7B with reported contexts from 32K to 1M and then analyze common failure modes. Quick summary of interesting results - All models tested except Mixtral fail to achieve baseline performance at their stated context size, GPT4 wins overall. - All models tested look great if only considering needle-in-a-haystack style tests, but struggle with more complex, realistic tasks in RULER. - There is a trade-off between baseline performance at small context size and relative performance degradation when scaling to larger contexts. - Common failure modes with increasing context are tendency to copy, unreliable reference tracing and hallucinations, among others. ğ—£ğ—®ğ—½ğ—²ğ—¿ ğ—–ğ—¼ğ—±ğ—² LLM context benchmarking technology machinelearning AI research computerscience",200,8,True,False,2024-05-25
507,https://www.linkedin.com/posts/activity-7199728340994277378-qSYR?utm_source=share&utm_medium=member_desktop&rcm=ACoAAC1jSQYB21OnvTZl_t_atKlYgs255ng7rVU,"Direct Nash Optimization DNO is a new LLM self-improvement technique describes by Corby Rosset et al. 2024 at Microsoft. DNO uses pairs of prompt responses which have been annotated by a teacher model to perform contrastive style reinforcement learning. After the first iteration, new preference pairs are constructed, including outputs sampled from the student model. The method achieves state-of-the art results in win rate over GPT-4-Turbo on AlpacaEval2.0 over other cutting edge models Figure 1, below  best win-rate and first to beat 30 win-rate and length corrected win-rate and outperforms other similar post-training techniques Figure 2, below  blue and purple traces. Nash equilibrium is a concept from game theory describing a state wherein no single player can gain by changing their strategy, assuming the other players strategies are fixed. ğ—£ğ—®ğ—½ğ—²ğ—¿ LLM NLP MachineLearning AI Research Technology SelfImprovement GameTheory NashEquilibrium",139,9,True,False,2024-05-24
303,https://www.linkedin.com/posts/activity-7199374757362860033-ZY7R?utm_source=share&utm_medium=member_desktop&rcm=ACoAAC1jSQYB21OnvTZl_t_atKlYgs255ng7rVU,"Coercing LLMs to do and Reveal Almost Anything by Jonas Geiping et al. presents a systematic investigation of common adversarial objectives found in LLM attacks. With LLaMA2-7b-chat as target, token based optimization is used to find attack strings which are successful in provoking profanity or misinformation, extracting model information such as system prompts, fishing for URLs, provoking unintended actions or even controlling the model. See table 1 below for examples profanity warning!. The authors categorize successful attack strings by underlying strategy as follows - ğ—¥ğ—²ğ—½ğ—¿ğ—¼ğ—´ğ—¿ğ—®ğ—ºğ—ºğ—¶ğ—»ğ—´ switching domains from natural language to code can sidestep alignment. - ğ—Ÿğ—®ğ—»ğ—´ğ˜‚ğ—®ğ—´ğ—² ğ˜€ğ˜„ğ—¶ğ˜ğ—°ğ—µğ—¶ğ—»ğ—´ use non-English languages to prompt alignment breaking generation in English. - ğ—¥ğ—¼ğ—¹ğ—² ğ—µğ—®ğ—°ğ—¸ğ—¶ğ—»ğ—´ trick/confuse the model into loosing track of its role  i.e. output is generated as user or system. - ğ—–ğ—®ğ—¹ğ—¹ğ˜€ ğ˜ğ—¼ ğ—®ğ—°ğ˜ğ—¶ğ—¼ğ—» directly asking/demanding dis-allowed actions, often repeatedly. - ğ—”ğ—½ğ—½ğ—²ğ—®ğ—¹ğ˜€ ğ˜ğ—¼ ğ—®ğ˜‚ğ˜ğ—µğ—¼ğ—¿ğ—¶ğ˜ğ˜† mentions of imaginary or irrelevant authority figures. ğ—£ğ—®ğ—½ğ—²ğ—¿ ğ—–ğ—¼ğ—±ğ—² ELLIS Institute TÃ¼bingen, Max Planck Institute for Intelligent Systems, University of Maryland technology machinelearning AI LLM research computerscience cybersecurity",170,7,True,False,2024-05-23
797,https://www.linkedin.com/posts/activity-7199012395065712641-eoCi?utm_source=share&utm_medium=member_desktop&rcm=ACoAAC1jSQYB21OnvTZl_t_atKlYgs255ng7rVU,"Benjamin Wolff et al. 2024 from ZB MED - Informationszentrum Lebenswissenschaften Information Center for Life Sciences, Cologne, Germany report a newly fine-tuned model which classifies scholarly publications according to Open Research Knowledge Graph taxonomy. The model consists of a fully fine-tuned SPECTER2 model fitted with a final, dense classification layer and is able to classify academic articles with an F1 score of 0.75, and increase of 7x compared to BERTbase without data enrichment. The model was created in response to the single-label, multi-class classification task at NLSP 2024. The training data source is 60k English language scientific papers from arXiv and ORKG and the authors add several external features, including keywords and journal titles from OpenAlex, Semantic Scholar Academic Graph and CrossRef. ğ—£ğ—®ğ—½ğ—²ğ—¿ ğ—–ğ—¼ğ—±ğ—² technology machinelearning AI languagemodels NLP NLSP2024 research scientificliterature classification BERT SPECTER2",135,11,True,False,2024-05-22
259,https://www.linkedin.com/posts/activity-7198653812788592640-6gwk?utm_source=share&utm_medium=member_desktop&rcm=ACoAAC1jSQYB21OnvTZl_t_atKlYgs255ng7rVU,"Yang Bai et al. 2024 at Tencent show that LLMs can be induced to leak training data with attack success rates reaching almost 50 in some cases. They employ a simple extraction strategy, using sequences of special characters generated by GPT-4. The victim models include LLaMA-2, LLaMA-3, Falcon-7.5B, ChatGLM-6B, ChatGPT, Gemini and ERNIEBot. ChatGPT appears most venerable to this type of attack overall. The most effective types and combinations of special characters vary by target model. Longer special character attack sequences are more effective, at least on ChatGPT and the leaked data reflects the composition of the training corpus. ğ—£ğ—®ğ—½ğ—²ğ—¿ technology machinelearning AI languagemodels NLP adversarialattacks trainingdataextraction security cybersecurity LLaMA Falcon ChatGPT Gemini",113,13,True,False,2024-05-21
408,https://www.linkedin.com/posts/activity-7198646396533567488-wina?utm_source=share&utm_medium=member_desktop&rcm=ACoAAC1jSQYB21OnvTZl_t_atKlYgs255ng7rVU,"News from Google IO 2024, you can now run Gemma locally via the new Firebase Genkit - a newly announced open source AI application framework from Google. Google AI gemma opensource tech GoogleIO",33,5,True,True,2024-05-21
1332,https://www.linkedin.com/posts/activity-7198306738326904833-OgU1?utm_source=share&utm_medium=member_desktop&rcm=ACoAAC1jSQYB21OnvTZl_t_atKlYgs255ng7rVU,"Ever seen a LLM spit out garbage? You might have stumbled on an under-trained token. Sander Land and Max Bartolo Cohere describe a new method for detecting under or un-trained tokens in their paper, Fishing for Magikarp Automatically Detecting Under-trained Tokens in Large Language Models. The under-training score is based on a mean unused token embedding vector derived from the models last, or un-embedding layer using a set of known-to-be unused embedding indices. The top 2 under-training scored tokens are enriched almost 30-fold for tokens which cause strange model output, depending on the specific model tested Figure 1, below. For models where training data statistics are available, a tokens under-training score is strongly related to its frequency in the training data Figure 2, below. The paper presents many interesting model specific observations for a host of open and closed source models. Here are my key takeaways - Under-trained tokens exist in most, if not all, models at 0.1-1 of the vocabulary. - Re-using an external tokenizer when ğ˜¥ğ˜¦ ğ˜¯ğ˜°ğ˜·ğ˜° training a base model is likely to yield a relatively large number of un-trained or under-trained tokens due to vocabulary mismatch. - There is a surprising to me amount of junk in tokenizer vocabularies - Tokenizer vocabulary and tokenizers in general dont get enough attention in wider discussions of LLMs that I have seen personally. ğ—£ğ—®ğ—½ğ—²ğ—¿ ğ—–ğ—¼ğ—±ğ—² technology machinelearning AI languagemodels NLP tokenizers vocabulary solidgoldmagikarp",234,8,True,False,2024-05-20
1287,https://www.linkedin.com/posts/activity-7197925210463838208-xVIr?utm_source=share&utm_medium=member_desktop&rcm=ACoAAC1jSQYB21OnvTZl_t_atKlYgs255ng7rVU,"Parth Sarthi et al. 2024 at Stanford University present a novel method to increase the performance of retrieval augmented generation systems. The method, termed RAPTOR, used a flattened tree of clustered chunks from the retrieval corpus which have iteratively been summarized by GPT-3.5-Turbo and re-clustered. This allows the reader LLM access to multiple levels of summarization and can juxtapose related information from different parts of the retrieval corpus. RAPTOR produces state-of-the art results on QASPER, outperforming LongT5 XL and CoLT5 XL. ğ—£ğ—®ğ—½ğ—²ğ—¿ ğ—–ğ—¼ğ—±ğ—² technology machinelearning AI languagemodels LLM RAG chatGPT",90,7,True,False,2024-05-19
415,https://www.linkedin.com/posts/activity-7197562822325678080-0DZV?utm_source=share&utm_medium=member_desktop&rcm=ACoAAC1jSQYB21OnvTZl_t_atKlYgs255ng7rVU,"Linjiao et al. 2023 at Stanford ask the question, How is ChatGPTs behavior changing over time?. To find an answer, the authors test the March 2023 and June 2023 snapshots of GPT-4 and GPT-3.5 on eight tasks to asses changes in performance and safety. They observe increased performance on some tasks and decreased performance on others. Interestingly, for some tasks, one model gets better while the other model gets worse. Big take-home is the specific snapshot of a given model you use matters a lot. Qualitatively, the results are as follows - GPT-4 changed more overall than GPT-3.5 - GPT-4s math abilities decreased while GPT-3.5s improved. - GPT-4s agent abilities improved while GPT-3.5s decreased slightly. - Both models code writing ability decreased. - GPT-4s response rate and answers to opinion based questions changed dramatically, GPT-3.5s less so. - Both models became safer as measured by willingness to answer sensitive questions. ğ—£ğ—®ğ—½ğ—²ğ—¿ ğ—–ğ—¼ğ—±ğ—² technology AI machinelearning chatGPT ethicalAI NLP openAI",159,7,True,False,2024-05-18
774,https://www.linkedin.com/posts/activity-7197200435529564160-W8uG?utm_source=share&utm_medium=member_desktop&rcm=ACoAAC1jSQYB21OnvTZl_t_atKlYgs255ng7rVU,"Meta-prompting is a new task  model agnostic method to use a single LLM simultaneously as a manager and a dynamic set of experts See example in figure 2, below. The approach is introduced by Mirac Suzgun Stanford University and Adam Tauman Kalai OpenAI. When used with GPT-4-32k, it improves performance on tasks which benefit from trial and error or heuristic approaches 15-60 over other prompting techniques such as zero-shot, chain of thought, expert and multi-persona prompting. Though some tasks see much less gain over baseline, the average improvement across all tasks is 18 table 1, below. ğ—£ğ—®ğ—½ğ—²ğ—¿ ğ—–ğ—¼ğ—±ğ—² AI MachineLearning LargeLanguageModels LLMs chatGPT NLP PromptEngineering",105,7,True,False,2024-05-17
439,https://www.linkedin.com/posts/activity-7197200430173409280-hLZi?utm_source=share&utm_medium=member_desktop&rcm=ACoAAC1jSQYB21OnvTZl_t_atKlYgs255ng7rVU,"Bevendorff et al. 2024 at Leipzig University ask the question Is Google Getting Worse? To find an answer, the authors scraped search results for reviews in common product categories from StartPage, Bing and DuckDuckGo every two weeks from October 2022 to September 2023. They then analyze the results for common SEO features, lexical complexity and the presence of affiliate links. ChatNoir and ClueWeb22B were used as baselines for naive bag-of-word search and the latent web at large respectively. Here are the key qualitative results ğ—¦ğ—˜ğ—¢ ğ˜„ğ—¼ğ—¿ğ—¸ğ˜€ Prevalence of common SEO features and affiliate links are a strong predictor of search result rank Figure 1 and pages with large amounts of affiliate links are more common in results from commercial search engines than baseline or the web at large Table 1 and Figure 2a. ğ—œğ˜ğ˜€ ğ—®ğ—» ğ—®ğ—¿ğ—ºğ˜€ ğ—¿ğ—®ğ—°ğ—² ğ—¯ğ—²ğ˜ğ˜„ğ—²ğ—²ğ—» ğ—¦ğ—˜ğ—¢ ğ—®ğ—»ğ—± ğ˜€ğ—²ğ—®ğ—¿ğ—°ğ—µ ğ—²ğ—»ğ—´ğ—¶ğ—»ğ—²ğ—²ğ—¿ğ˜€ Ranker updates tend to remove low quality, highly SEO-ed content from spam and review farm domains only for it to re-appear later on Figure 3. ğ—šğ—¼ğ—¼ğ—´ğ—¹ğ—² ğ—¶ğ˜€ ğ—¹ğ—¼ğ—¼ğ˜€ğ—¶ğ—»ğ—´ ğ—¶ğ˜ğ˜€ ğ—²ğ—±ğ—´ğ—² At the beginning of the study period Google search via StartPage returned the lowest number of high affiliate link count results, but didnt gain or loose any ground, while the number of high affiliate link count results returned by Bing and DuckDuckGo decreased Figure 2a, below. ğ—–ğ—¼ğ—»ğ˜ğ—²ğ—»ğ˜ ğ—¾ğ˜‚ğ—®ğ—¹ğ—¶ğ˜ğ˜† ğ—ºğ—®ğ˜† ğ—¿ğ—²ğ—®ğ—¹ğ—¹ğ˜† ğ—¯ğ—² ğ—±ğ—²ğ—°ğ—¿ğ—²ğ—®ğ˜€ğ—¶ğ—»ğ—´ The 95th percentile of type-token ratio decreased 10 across the study period for all three search engines, indicating that search results are becoming less lexically complex and more repetitive over time Figure 2b, below. There are many interesting observations and a lot of useful background on the subject in the paper, especially if you are new to the topic of quantitative internet research like I was. I highly recommended you give it a read, if you havent already. ğ—£ğ—®ğ—½ğ—²ğ—¿ ğ—–ğ—¼ğ—±ğ—² SEO Google StartPage DuckDuckGo Bing search searchengines affiliatemarketing",312,8,True,False,2024-05-17
957,https://www.linkedin.com/posts/activity-7196883344909836288-Up9j?utm_source=share&utm_medium=member_desktop&rcm=ACoAAC1jSQYB21OnvTZl_t_atKlYgs255ng7rVU,"Ever wonder if the thing you are reading was written by a human or generated by a large language model? Abhimanyu Hans  Avi Schwarzschild, et al. 2024 at the University of Maryland  Carnegie Mellon University respectively, present Binoculars  a novel model and agnostic machine-generated text detection strategy. Binoculars uses a ratio of the suspect texts perplexity score to the perplexity score of next-token predictions on the suspect text to outperform previous methods of synthetic text detection. The method reliably detects 75 and often much greater of synthetic text examples generated by GPT-3.5-turbo, LLaMA-2-13B or Falcon-7B. ğ—£ğ—®ğ—½ğ—²ğ—¿ ğ—–ğ—¼ğ—±ğ—² machinelearning languagemodels synthetictextdetection AI LLMs education technology",104,7,True,False,2024-05-16
1697,https://www.linkedin.com/posts/activity-7191768389885825025-FZ4w?utm_source=share&utm_medium=member_desktop&rcm=ACoAAC1jSQYB21OnvTZl_t_atKlYgs255ng7rVU,"Self-rewarding language models, described by Weizhe Y. et al. 2024, Meta  New York University use the model-in-training as its own reward function. LLaMA2 70B is used as a starting point and fine-tuned with human authored instruction-response and instruction-response evaluation data. The model is then used to generate and evaluate synthetic instruction-response prompts, thereby creating new data for subsequent rounds of training. The approach results in continued improvement in a head-to-head performance challenge over three rounds of self-reward training Figure 5, human evaluation shown below. ğ—£ğ—®ğ—½ğ—²ğ—¿ AI machinelearning LLaMA2 largelanguagemodels NLP science",91,6,True,False,2024-05-02
4591,https://www.linkedin.com/posts/activity-7191108110835437568-OgvC?utm_source=share&utm_medium=member_desktop&rcm=ACoAAC1jSQYB21OnvTZl_t_atKlYgs255ng7rVU,"Zixiang Chen et al. 2024 at UCLA ask, can an LLM improve itself without additional external data? The answer is yes, up to a point. Their method, self-play fine-tuning SPIN, uses an adversarial strategy to iteratively train a model on synthetic data from a prior checkpoint of the same model and the data that was used to train that checkpoint. Think self GAN. SPIN results in a 9 improvement in average HuggingFace open LLM leaderboard score over 4 iterations. SPIN iterations are better than more fine-tuning epochs alone and out-perform similar approaches such as direct performance optimization. ğ—£ğ—®ğ—½ğ—²ğ—¿ ğ—–ğ—¼ğ—±ğ—² LLMs SPIN GANs DPO syntheticdata selfimprovement Hugging Face Mistral AI",109,6,True,False,2024-04-30
262,https://www.linkedin.com/posts/activity-7190825011618660352-Pp5H?utm_source=share&utm_medium=member_desktop&rcm=ACoAAC1jSQYB21OnvTZl_t_atKlYgs255ng7rVU,"Cheyenne Supercomputer on auction - current bid is 6,000. Anyone want to split it with me? Has 8,064 18 core Xeon processors from 2016 and 313,344 GB DDR4. Listing supercomputer xeon cheyenne AIstartup justkidding",34,5,True,False,2024-04-29
2756,https://www.linkedin.com/posts/activity-7190721665314533378-qte1?utm_source=share&utm_medium=member_desktop&rcm=ACoAAC1jSQYB21OnvTZl_t_atKlYgs255ng7rVU,"How good are Low-bit quantized LLaMA3 models? Wei Huang and Xudong Ma, et al. 2024 Present results from post-training quantization PTQ and low rank adaptation LoRA fine-tuning of LLaMA3 8B and 70B on a range of perplexity and common sense question answering benchmarks. Here is my quick-and-dirty summary of the results - With no real degradation of performance, LLaMA3 8B can be quantized to 8 bits and LLaMA3 70B to 6 bits using PTQ techniques. - With 2-2.5 fold increase in perplexity and 20-25 decrease in common sense question answering scores, LLaMA3 8B can be quantized to 2 bits and LLaMA3 70B to 4 bits using PTQ techniques. - Both models tend to suffer a total breakdown when quantized at the 2-bit level during PTQ. - LoRA fine-tuning of LLaMA3 8B just barely matches or under performs when compared to PTQ at the 4-bit level. ğ—£ğ—®ğ—½ğ—²ğ—¿ ğ—–ğ—¼ğ—±ğ—² LLMs LLaMA3 quantization finetuning machinelearning AI",153,6,True,False,2024-04-29
435,https://www.linkedin.com/posts/activity-7189590289299177473-q7fs?utm_source=share&utm_medium=member_desktop&rcm=ACoAAC1jSQYB21OnvTZl_t_atKlYgs255ng7rVU,"Nice review of synthetic data in language models from Ruibo Liu et al. Google DeepMind. They identify some great case studies of uses for synthetic data in training and evaluation as well as some interesting challenges and directions for future work. Most of the problems boil down to some twist on poisoning the well e. g. proliferating misinformation, dilutions of human nuance and perspective or contamination of evaluation data. Some interesting future directions and open questions discussed - New methods to improve synthetic data generation. - New ways to take advantage of the fine-grained control over training corpora that synthetic data offers - Scaling does a large amount of synthetic data beat a smaller amount of real data? - Self improvement is it possible for a model to generate synthetic data that is better than the data it was trained on? ğ—£ğ—®ğ—½ğ—²ğ—¿ LLMs trainingdata syntheticdata machinelearning generativeAI",147,5,True,True,2024-04-26
2013,https://www.linkedin.com/posts/activity-7189227901358100480-bAwo?utm_source=share&utm_medium=member_desktop&rcm=ACoAAC1jSQYB21OnvTZl_t_atKlYgs255ng7rVU,"Looking at a pair of sister papers from Google DeepMind today Soham De et al. 2024 introduces a new language model architecture known as Griffin and Aleksandar Botev et al. 2024 presents RecurrentGemma the new open source model family based on the Griffin architecture. The goal of the new architecture is to address the problems inherent in transformers when scaling to long input sequences by replacing multi-query attention with a new gated linear recurrent layer. The Griffin architecture is able to maintain the accuracy of next token prediction longer than baseline transformer models De 2024 Figure 5a, below and continue to benefit from longer training sequences De 2024 Figure 5b, below. Other model characteristics such as benchmark performance, training speed and inference latency and throughput are also favorable when compared to transformer models. ğ——ğ—² ğ—²ğ˜ ğ—®ğ—¹. ğŸ®ğŸ¬ğŸ®ğŸ° ğ—•ğ—¼ğ˜ğ—²ğ˜ƒ ğ—²ğ˜ ğ—®ğ—¹. ğŸ®ğŸ¬ğŸ®ğŸ° ğ—–ğ—¼ğ—±ğ—² ğ— ğ—¼ğ—±ğ—²ğ—¹ğ˜€ LLMs transformers multiqueryattention recurrentneuralnetworks Griffin RecurrentGemma",149,6,True,False,2024-04-25
1503,https://www.linkedin.com/posts/activity-7188865521260322817-SzsI?utm_source=share&utm_medium=member_desktop&rcm=ACoAAC1jSQYB21OnvTZl_t_atKlYgs255ng7rVU,"Lin et al. Microsoft Research Asia present a simple and apparently effective technique to increase the training speed and performance of LLMs termed Selective Language Modeling. The method uses a reference model to calculate a loss score for each token in the pretraining corpus. Then, the selective language model is trained only on tokens that have high loss relative to their loss score from the reference model. This results in faster training to baseline performance and higher than baseline performance given longer training See Figure 1a below. The selective language model is also competitive with larger models trained on many more tokens in chain of thought and tool-integrated reasoning tasks. Since this method is essentially filtering out low quality tokens, I wonder if the results would generalize to other pretraining datasets and other types of tasks? ğ—£ğ—®ğ—½ğ—²ğ—¿ ğ—–ğ—¼ğ—±ğ—² ğ— ğ—¼ğ—±ğ—²ğ—¹ğ˜€ NLP LLMs SelectiveLanguageModeling",142,3,True,False,2024-04-24
365,https://www.linkedin.com/posts/activity-7188503121357144065-YiU9?utm_source=share&utm_medium=member_desktop&rcm=ACoAAC1jSQYB21OnvTZl_t_atKlYgs255ng7rVU,Tom Sander et al. AI at Meta investigate the transmission of watermarking from dataset to LLM and LLM to LLM. They find it is possible to detect that a suspect model has been fine-tuned on output from a watermarked model with high confidence when  5 of the fine-tuning data originated from the watermarked model. See Closed  Unsup in Figure 4 shown below. This condition represents the most challenging and realistic scenario where the fine-tuning data is not available and the suspect model is closed source. Seems like Meta has a pretty serious interest in being able to tell if/when folks are using their models to generate synthetic training data. Paper LLMs NLP watermarking syntheticdata finetuning,115,5,True,False,2024-04-23
882,https://www.linkedin.com/posts/activity-7188290605041557504-Eb8H?utm_source=share&utm_medium=member_desktop&rcm=ACoAAC1jSQYB21OnvTZl_t_atKlYgs255ng7rVU,"Good news for the space exploration and technology enthusiasts out there - NASA just announced that Voyager 1 is sending interpretable engineering data home again! Since Nov. 14 of last year, it hadnt sent back any intelligible data and there was some concern that it wouldnt make it to the big 50 year mark in 2027. Congrats to the engineers! Can you imagine what it would be like to troubleshoot a 47 year old custom designed, bespoke computer system from 15 billion miles away? NASA Voyager1 space science",88,4,True,False,2024-04-22
459,https://www.linkedin.com/posts/activity-7188140738386305024-fISt?utm_source=share&utm_medium=member_desktop&rcm=ACoAAC1jSQYB21OnvTZl_t_atKlYgs255ng7rVU,Bolton et al. Stanford University and Databricks report a new autoregressive LLM trained on biomedical scientific literature from PubMed paired with a custom tokenizer. The model is open source and can handle multiple choice and short answer biomedical and clinical questions better than generalist models of similar size. The new model is also competitive with 100B parameter models on some tasks. Paper Model Code biomedical LLMs PubMed,67,3,True,False,2024-04-22
1166,https://www.linkedin.com/posts/activity-7186328798664044546-Kfvw?utm_source=share&utm_medium=member_desktop&rcm=ACoAAC1jSQYB21OnvTZl_t_atKlYgs255ng7rVU,"Looking for a good way to get some hands-on practice with git? Try Oh My Git! This very cool open source game by bleeptrack and blinry provides levels to work through many common git operations while visualizing the commit graph in real time, including interacting with remotes. Since the game is built on top of git, you can also execute any command and see the result. git versioncontrol collaboration opensource learningtools",71,5,False,True,2024-04-17
204,https://www.linkedin.com/posts/activity-7185966410592923650-tMo3?utm_source=share&utm_medium=member_desktop&rcm=ACoAAC1jSQYB21OnvTZl_t_atKlYgs255ng7rVU,Very cool blog post by Martin Heinz - make better use of your shell history than just pressing up repeatedly! Linux shell bash zsh productivity,25,5,True,True,2024-04-16
232,https://www.linkedin.com/posts/activity-7185596286673260544-2lsY?utm_source=share&utm_medium=member_desktop&rcm=ACoAAC1jSQYB21OnvTZl_t_atKlYgs255ng7rVU,"Cool ensemble method presented by Junyou Li et al. Tencent. Reminds me a little of bagging for decision trees models vote via BLEU score to determine the final output. Results in a 4-24 improvement over a single model. Works across models and tasks and gains stack with other similar methods. I like the simplicity and ease of application. ğ— ğ—¼ğ—±ğ—²ğ—¹ğ˜€ ğ˜ğ—²ğ˜€ğ˜ğ—²ğ—± LLaMA2-13B, LLaMA2-70B, GPT3.5-Turbo ğ—§ğ—®ğ˜€ğ—¸ğ˜€ ğ—²ğ˜ƒğ—®ğ—¹ğ˜‚ğ—®ğ˜ğ—²ğ—± GSM8K, MATH, MMLU, chess state tracking, HumanEval ğ—¢ğ˜ğ—µğ—²ğ—¿ ğ—¼ğ—¯ğ˜€ğ—²ğ—¿ğ˜ƒğ—®ğ˜ğ—¶ğ—¼ğ—»ğ˜€ smaller, less powerful models seem to benefit more, especially on more challenging tasks. Paper LLMs NLP machinelearning ensemblemethods",92,4,True,False,2024-04-15
170,https://www.linkedin.com/posts/activity-7185585266802225153-IN_x?utm_source=share&utm_medium=member_desktop&rcm=ACoAAC1jSQYB21OnvTZl_t_atKlYgs255ng7rVU,"Just learned about Lore Harp McGovern. Amazing story and a good read. She started building memory and other computer parts from her home in the 70s, while raising two kids. Built one of the first public microcomputer companies, beating out IBM and becoming an original founder of Silicon Valley. tech history entrepreneurship DIY",53,4,True,True,2024-04-15
153,https://www.linkedin.com/posts/activity-7184562158125379584-8HwO?utm_source=share&utm_medium=member_desktop&rcm=ACoAAC1jSQYB21OnvTZl_t_atKlYgs255ng7rVU,Here is something just for fun grow a bonsai tree in your terminal. Any other frivolous terminal apps you know of? Happy Friday!,23,0,True,False,2024-04-12
313,https://www.linkedin.com/posts/activity-7184516859356979201-frxF?utm_source=share&utm_medium=member_desktop&rcm=ACoAAC1jSQYB21OnvTZl_t_atKlYgs255ng7rVU,"Can transformers learn to use compute resources more efficiently? Turns out, they can - David Raposo et al. use a per-block learned routing mechanism to send each token either through or around the block. The resulting smaller computational footprint relative to a vanilla transformer allows Mixture-of-Depths models to achieve - Similar performance at lower computational cost. - Better performance at the same computational cost. - Better performance overall. Paper transformers NLP machinelearning Google DeepMind",74,3,True,False,2024-04-12
412,https://www.linkedin.com/posts/activity-7184163684657573888-kdvL?utm_source=share&utm_medium=member_desktop&rcm=ACoAAC1jSQYB21OnvTZl_t_atKlYgs255ng7rVU,"Check out some amazing LLM BASH one-liners with llamafile by Justine Tunney. Im continually impressed by how easy it has become to use LLMs - and how quickly its getting easier and faster. There are a bunch of cool examples in the link, including image renaming, link summarization and code completion, among others. LLM llamacpp llamfile linux shell",58,5,True,True,2024-04-11
261,https://www.linkedin.com/posts/activity-7183764840144850944-wwpd?utm_source=share&utm_medium=member_desktop&rcm=ACoAAC1jSQYB21OnvTZl_t_atKlYgs255ng7rVU,The Mixtral-8x-22B-v0.1 sparse mixture-of-experts model is out! It was puahed to HuggingFace a few hours ago. Here is the model card LLMs mixtureofexperts MistralAI mixtral huggingface transformers,27,6,True,True,2024-04-10
305,https://www.linkedin.com/posts/activity-7183760763293945856-cYwX?utm_source=share&utm_medium=member_desktop&rcm=ACoAAC1jSQYB21OnvTZl_t_atKlYgs255ng7rVU,Airbnb just open sourced their feature/data engineering platform called Chronon. airbnb stripe machinelearning featureengineering dataengineering MLengineering python airflow opensource,19,9,True,True,2024-04-10
230,https://www.linkedin.com/posts/activity-7181613583615565824-CBdp?utm_source=share&utm_medium=member_desktop&rcm=ACoAAC1jSQYB21OnvTZl_t_atKlYgs255ng7rVU,What reference manager is everyone using? I used Endnote and then Zotero though grad school. Thinking about giving JabRef a try. I like the option to use your own self-hosted SQL server for the library. Any thoughts or other suggestions? refrencemanagers academicpublishing scientificlliterature,43,3,True,True,2024-04-04
286,https://www.linkedin.com/posts/activity-7181277403954970624-6xyR?utm_source=share&utm_medium=member_desktop&rcm=ACoAAC1jSQYB21OnvTZl_t_atKlYgs255ng7rVU,Have you seen something like this? Look closely. I want NLP/LLMs to be a net benefit for everyone and I think they can be - but what the heck is wrong with peer review? peerreview academia generativeAI ethics,38,4,True,True,2024-04-03
392,https://www.linkedin.com/posts/activity-7180175287588945920-d5JS?utm_source=share&utm_medium=member_desktop&rcm=ACoAAC1jSQYB21OnvTZl_t_atKlYgs255ng7rVU,"What a cool dataset! Over 13k 3D CT and/or laser scan meshes of vertebrates representing 80 of existant genera. Not sure what to do with it, but I feel like theres an interesting project or two to be had here. What do you think? biology biodiversity dataset computedtomography",48,4,True,True,2024-03-31
588,https://www.linkedin.com/posts/activity-7179786929737994240-HS6Q?utm_source=share&utm_medium=member_desktop&rcm=ACoAAC1jSQYB21OnvTZl_t_atKlYgs255ng7rVU,If you are running sshd - especially publicly - update ASAP. The xz library versions 5.6.0 and 5.6.1 contain a malicious backdoor which causes SSH vulnerability. linux cybersecurity ssh xz lzma,31,5,False,False,2024-03-30
529,https://www.linkedin.com/posts/activity-7179109113363083265-LeG4?utm_source=share&utm_medium=member_desktop&rcm=ACoAAC1jSQYB21OnvTZl_t_atKlYgs255ng7rVU,Excited to announce that my project Bartleby was just named a Backdrop Build V3 Finalist! Thanks to the organizers and congrats to the other builders. Looking forward to future build competitions and continuing to improve Bartelby. LLMs Python Hugging Face Discord Element,42,2,False,False,2024-03-28
